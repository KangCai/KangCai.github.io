---
layout: post
title: "机器学习·总览篇 V"
subtitle: "三要素之模型"
author: "Kang Cai"
header-img: "img/post-bg-dreamer.jpg"
header-mask: 0.4
tags:
  - 机器学习
  - 机器学习·总览篇
---

> 上一篇文章介绍了机器学习的三要素-模型、策略、算法，但只是比较粗略地介绍，本文将着重介绍三要素之模型，视角主要放在不同模型间的区别

> 本文首发于我的知乎专栏[《机器怎么学习》](https://zhuanlan.zhihu.com/machine-learning-complete)中 [机器学习·总览篇(5) 三要素之模型](https://zhuanlan.zhihu.com/p/48914251)，转载请保留链接 ;)

### 模型

机器学习首要考虑的问题是学习什么样的模型，如在《机器学习·总览篇(4) 机器学习的三要素》中描述的，模型就是所要学习的条件概率分布或决策函数。模型的假设空间（hypothesis space）包含所有可能的条件概率分布和决策函数，一般是无限多种可能性，训练（数据经过模型、策略、算法的处理，对模型的参数进行调整）的目的就是获取一个最优参数的模型。

模型通常可进行如下分类，

* 分类方法一：判别模型（Discriminative Model）和 生成模型（Generative Model），两者互斥

* 分类方法二：概率模型（Probabilistic Model）和 非概率模型（Non-probabilistic Model），两者互斥

具体关系如图1所示，

<center>
<img src="https://kangcai.github.io/img/in-post/post-ml/Model classification.png"/>
</center>
<center>图1 模型分类示意图</center>

从图1可以看到，上述两种分类方法相当于把所有模型划分成了三类，

1. 非概率模型：直接对输入空间到输出空间的映射y=h(x)建模；直接完成目标且只能解决目标任务。实例：感知机（单层神经网络，Perceptron）、多层感知机（MLP）、支持向量机（SVM）、K近邻（KNN）

2. 概率判别模型：对后验概率P(y\|x)建模，然后实现分类；不仅能完成任务目标，而且能给出后验概率。实例：逻辑回归（LR）、最大熵模型（ME）、条件随机场（CRF）

3. 生成模型：先对联合概率P(x,y)建模，再根据贝叶斯公式算出条件概率P(y\|x)，最后实现分类；不仅能完成任务目标，给出后验概率，而且还能给出联合概率。实例：高斯判别分析（GDA）、朴素贝叶斯（NB）、受限玻尔兹曼机（RBM）、隐马尔科夫模型（HMM）

一个stackoverflow的简单例子能很好地说明以上三种方法。假设特征x是1维，并且值只有1和2可选；标签y的也是1维，且值只有0和1可选，现在有如下 (x,y) 形式的4个样本 - (1,0)、(1,0)、(1,1)、(2, 1)，则学习到的联合概率分布（对应第3类模型，即生成模型）如下：

|  | y = 0 | y = 1| 
| :-----------:| :----------: | :----------: |
| x = 1 |1/2|1/4|
| x = 2 |0|1/4|

而学习到的条件概率分布（对应第2类模型，即概率判别模型，既是概率模型，又是判别模型）如下：

|  | y = 0 | y = 1| 
| :-----------:| :----------: | :----------: |
| x = 1 |2/3|1/3|
| x = 2 |0|1|

而学习到的直接映射（对应第1类模型，即非概率模型）如下：

|  | y = 0 | y = 1| 
| :-----------:| :----------: | :----------: |
| x = 1 |1|0|
| x = 2 |0|1|

可以很清楚地看到信息量从多到少：生成模型 \> 概率判别模型 \> 非概率模型。更全面地总结可用下表表示：

|  | 步骤 | 数据量 | 作用（模型信息量） | 准确率 | 示例
| :-----------:| :----------: | :----------: | :----------: | :----------: | :----------: |
| 非概率模型 | 直接分类| 少 | 分类 | 相对较高| SVM/NN/KNN |
| 概率判别模型 | 后验概率-分类| 中 | 分类/后验概率 | 相对较高|LR/ME/CRF |
| 生成模型 |联合概率-后验概率-分类| 多 | 分类/后验概率/联合概率 |相对较低| GDA/NB/HMM |

下面具体介绍三种类型的模型

### 判别模型：非概率模型 + 概率判别模型

如上文所说，判别模型包括了非概率模型和概率判别模型。如下为判别模型的分类示意图，

<center>
<img src="https://kangcai.github.io/img/in-post/post-ml/data_visual-dm.png"/>
</center>
<center>图1 判别模型分类示意图</center>

如图所示，分类任务中，判别模型都有一个如图中划分数据的线一样的判别标准。这个判别标准对于非概率模型和概率判别模型来说有如下区别：

1. 非概率模型的判别标准是一个超平面，超平面分割数据起到判别作用；
2. 概率判别模型的判别标准是一个由条件概率表示的判别函数，根据条件概率的值大小比较起到判别作用。

##### 非概率模型

典型的非概率模型有支持向量机（SVM）和神经网络（NN），解决线性可分数据集的分类问题，是从点到超平面的距离角度建模。以线性SVM和感知机（单层NN）为例，

当然它可以有分类置信度的衡量指标，但该指标非后验概率罢了。


##### 概率判别模型

典型的概率判别模型有逻辑回归（LR）和最大熵模型（Maximum Entropy Model，ME），解决线性可分数据集的分类问题，是从条件概率的角度建模。以LR为例：




### 生成模型


<center>
<img src="https://kangcai.github.io/img/in-post/post-ml/data_visual-gm.png"/>
</center>
<center>图1 生成模型分类示意图</center>

1. [《统计学习方法》 李航][1]
3. [Stanford CS 229 ― Machine Learning][3]
9. [jianshu: 机器学习面试之最大熵模型] [9]

[1]: (https://book.douban.com/subject/10590856/)
[3]: (https://stanford.edu/~shervine/teaching/cs-229.html)
[9]: (https://www.jianshu.com/p/e7c13002440d)