---
layout: post
title: "机器学习·总览篇(4)"
subtitle: "机器学习的三要素"
author: "Kang Cai"
header-img: "img/post-bg-dreamer.jpg"
header-mask: 0.4
tags:
  - 机器学习
  - 机器学习·总览篇
---

> 从基本理论上看，如前一篇介绍统计推断的文章所说，统计推断是机器学习十分重要的理论基础，所以机器学习狭义上就是指代统计学习方法；从方法框架上看，机器学习（统计学习方法）的组成有三个要素：模型、策略和算法。我们通常接触到的所谓“深度学习”、“支持向量机”、“罗吉斯蒂克回归”、“决策树”等等，都离不开这三要素。毫不夸张的说，学习机器学习的关键，就是掌握它这三个要素。

> 本文首发于我的知乎专栏[《机器怎么学习》](https://zhuanlan.zhihu.com/machine-learning-complete)中 [机器学习·总览篇(4) 机器学习的三要素](https://zhuanlan.zhihu.com/p/48521073)，转载请保留链接 ;)

### 一、机器学习的三要素

数据在机器学习方法框架中的流动，会按顺序经历三个过程，分别对应机器学习的三大要素：1. 模型；2. 策略；3. 算法

* 模型：谈到机器学习，经常会谈到“模型”这个概念。**模型的实质是一个假设空间（hypothesis space），这个假设空间是“输入空间到输出空间所有映射”的一个集合。机器学习通过“数据+三个过程”，理论目标是获得假设空间的一个最优解，翻译一下就是求模型的最优参数**。

* 策略：

* 算法：

### 二、模型

##### 2.1 判别模型和生成模型

一般来说，机器学习模型会分为判别模型（Discriminative Model）和生成模型（Generative Model）两类。

判别模型更常用，感知机（Perceptron）、罗吉斯蒂克回归（LR）、支持向量机（SVM）、神经网络（NN）、K近邻（KNN）、线性判别分析（LDA）、Boosting、条件随机场（CRF）模型都属于判别模型。判别模型本身又分为两类：（1）直接对输入空间到输出空间的映射建模；（2）对条件概率P(y|x)建模，再分类。

生成模型是一种更加间接的建模，高斯判别分析（GDA）、朴素贝叶斯（NB）、文档主题生成模型（另外一个LDA，跟线性判别分析的LDA是完全不同的两个概念）、受限玻尔兹曼机（RBM）、隐马尔科夫模型（HMM）属于生成模型。分三步：先对联合概率P(x,y)建模，再根据贝叶斯公式算出P(y|x)，最后再分类。

以上提到了很多种当前热门的机器学习模型，有不了解的也不要紧，在后面的文章都会一一介绍。而所谓的深度学习，它的深度神经网络模型（DNN）也只是众多机器学习模型中的一类：卷积神经网络（CNN）、循环神经网络（RNN）、多层感知机（MLP）、堆叠自编码器（SAE）、堆叠受限玻尔兹曼机（有一个专门名字深度置信网络，DBN），以及以上各种模型的变形和扩展，它们都只是针对特定的问题和当前的高性能计算时代而诞生，没必要神化。为了方便起见，后文提到的某些模型的名称用惯用简写来表示。

回到判别模型和生成模型，学术界求条件概率P(y|x)的方法应该直接建模还是间接建模有分歧，SVM大佬Vapnik的观点觉得生成模型的第一步先对联合概率P(x,y)建模没必要，对P(y|x)直接进行建模就行了；业界大佬Andrew Ng力挺生成模型，他认为对P(x,y)进行建模从而达到判别的目的也有它自身的一些优势。

##### 2.2 判别模型和生成模型

另一种分类方式将判别模型（2）方法即先求条件概率的方法和生成模型先求联合概率的方法作为一类，称之为概率模型；将判别模型（1）方法即直接建模的方法分为另一类，称之为非概率模型。

概率模型由条件概率分布P(y|x)表示。所有生成模型都是概率模型，除此之外，判别模型中的LR、条件随机场（CRF）等属于概率模型。概率模型指出了学习的目的是学出联合概率P(x,y)或条件概率P(y|x)，其中联合概率通过贝叶斯公式P(x,y)=P(x|y)P(y)拆分成P(x|y)和P(y)分别进行估计。无论是P(y|x)、P(x|y)还是P(y)，都是会先假设分布的形式，例如LR就假设了 y|x 服从伯努利分布，线性回归假设了误差项服从均值为0的高斯分布。

非概率模型由决策函数y=h(x)表示。判别模型中感知机、SVM、神经网络、KNN都属于非概率模型。

### 三、策略

### 四、算法

参考文献

1. [《统计学习方法》 李航][1]
2. [On Discriminative vs. Generative classifiers: A comparison of logistic regression and naive Bayes. AY Ng 2002][2]

[1]: (https://book.douban.com/subject/10590856/)
[2]: (https://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf)
